---
title: "Understanding Fire Severity in California"
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

# change this to the location of your Quarto file containing your project; then delete this comment
here::i_am("Analysis.qmd")
```

The devastating series of wildfires in Los Angeles County earlier this January inspired me to focus my final project on analyzing fire incidents across California counties over the past 12 years. This project aims to explore key relationships between predictor variables and the severity of wildfires, measured by acres burned, while also developing a predictive model to anticipate future fire impacts. In addition to model-building, I’m investigating several important inference questions that reflect real-world concerns:

-   Does the severity of a wildfire depend on the season of the year?

-   Are wildfires in California worsening over time in terms of severity?

-   Are there specific counties in California where wildfires are more likely to occur?

By addressing these questions, I hope to better understand the patterns behind wildfire behavior—an understanding that could be crucial in shaping actuarial risk models and insurance strategies in the future.

This problem is especially compelling to me because I am majoring in Mathematics with a concentration in Actuarial Science and intend to pursue the Casualty Actuarial Society (CAS) track within the Property and Casualty insurance industry. As someone preparing for a career focused on analyzing risk and uncertainty, I believe that understanding the severity of fires in California, even if only measured by acres burned, is relevant for my career. Wildfires play a significant role in shaping Homeowners Insurance, both in terms of pricing and coverage availability. By studying this issue more deeply, I hope to gain insights that will one day allow me to develop more accurate predictive models and contribute to effective risk management strategies. Understanding these patterns isn’t just academically interesting—it directly aligns with my long-term professional goals of helping insurers and communities better prepare for and respond to natural disasters.

[**Note**]{.underline}**:** For context, it is important to note the key difference between the severity being measured in this project and the severity in insurance rate making.

In this project, we are defining severity as how destructive a fire is based on the length it impacted, disregarding other factors:

$$
\text{Severity} = \text{Amount of acres burned by a fire}\
$$

In insurance rate making, severity refers to the average cost of a claim:

$$
\text{Severity} = \frac{\text{Total Loss Amount}}{\text{Number of Claims}}
$$

[**OBS**]{.underline}: This clarification will definitely be helpful for actuaries and insurance professionals.

## Main Objective

I believe the insights gained from my analysis should be only considered could be highly relevant for the State of California and its residents, as wildfires continue to threaten countless homes and families each year. Addressing this issue allows me to connect my career aspirations with a real opportunity to contribute to the well-being of those affected by this recurring and devastating disaster. The inferences drawn from my data analysis have the potential to inform better predictive models and encourage continuous improvement in wildfire risk assessment. Ultimately, I hope my work can serve as a small but meaningful step toward helping communities prepare for, mitigate, and recover from the growing threat of wildfires.

## Packages

```{r packages used for data analysis}
#| label: load packages
#| message: false
#| warning: false

library(here)
library(readr)
library(dplyr)
library(rsample)
library(ggplot2)
library(recipes)
library(naniar)
library(broom)
library(lubridate)
library(tidyr)
library(janitor)
```

| Package | Function |
|--------------------------------|----------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs |
| [recipes](https://recipes.tidymodels.org/) | to define and apply data transformation steps |
| [naniar](https://naniar.njtierney.com/) | for visualizing and handling missing data |
| [broom](https://broom.tidymodels.org/) | for visualizing and handling missing data |
| [lubridate](https://lubridate.tidyverse.org/) | to simplify working with dates and times |

## Data Description

I am using the fire incident data available at the [CAL FIRE website](https://www.fire.ca.gov/incidents). CalFIRE (California Department of Forestry and Fire Protection) is California’s state agency responsible for fire protection in State Responsibility Areas (SRAs), which include over 31 million acres of wild lands and areas with significant natural resources. CAL FIRE also provides emergency services in cooperation with local governments and handles forest management, fire prevention, and resource protection.

All of the agency's information comes from the fire lines and must be approved by the Incident Commander in charge of managing the incident prior to release. The data then gets compiled by their staff and published in their website for the public to access. In their incidents page, there is a Current Emergency Incidents section where it shows fire related information such as evacuation orders and acres burned through Earthstar Geographics powered by [Esri](http://www.esri.com/), [Genasys](https://protect.genasys.com/search?z=14&latlon=38.134148%2C-121.272219) and [Perimeter](https://perimeterplatform.com/). However, since I needed the whole historical fire data set to perform my analysis , I collected the CSV file, they offered.

The main reasons why they collect the fire incident data includes fastening fire responsiveness, prevention of future fires, to inform the public through statistics, and to create an incentive for more funding towards fire prevention.

[**OBS**]{.underline}**:** It is important to note that the original excel file from CalFIRE contained significant amount of unnecessary raw data, and some wrong/outdated information. Therefore, this will be taken care of in our [**Data Wrangling**]{.underline} section to ensure our Analysis is as precise and professional as possible.

```{r}
#| label: import data
#| warning: false
#| message: false

original_fire <- readr::read_csv(here::here("mapdataall.csv"))

#original historical fire data from CalFIRE
```

### Data Limitations

CalFIRE makes it clear in their disclaimer that the data provided is intended for general reference rather than detailed scientific or emergency analysis. Therefore, important limitations must be considered when interpreting my model’s conclusions.

**1) Bias in data collection:** One possible source of bias is the fact that CalFIRE reportedly shared that a significant amount of small fires could go under reported, even more so if the incident burns less than 10 acres. Furthermore, another source of bias can be explained by how I performed variable selection during the modeling process. Since I got the data before specifing my linear model, I must account for selection bias.

**2) Variables Mismatches:** The outcome variable in our linear model, acres_burned is the only variable being used in my analysis to define the severity of the fire incidents. However, we are excluding so many crucial variables that influence a fire severity in the real-world such as structures destroyed, rural/urban differences, fire escalation, lack of firefighters, area accessibility, injuries, fatalities, more expensive/cheaper neighborhoods, total loss, and more. Plus, the variables incident_season and incident_county are very broad. I am not accounting for local weather, vegetation, source of fire, and human factors that could influence a fire behavior in the real-world.

**3) Model Transferrability:** My model is only accounting for fires in California in the past 12 years. Hence, the model might be inappropriate for other regions that present different weather, air humidity, terrain, biodiversity, population demographics, government funding, and more.

## Data Wrangling

### Data Clean Up

First of all, I must make sure this data set contains only historical fire data. CalFIRE predominantly oversee fire incidents but not exclusively. After some digging in `incident_type`, there were indeed two incidents reported as flood and one as earthquake. Hence, let's remove them from our original data set and change the updated data set name for good practice.

```{r}
fire_data <- original_fire %>%
  filter(!incident_type %in% c("Flood", "Earthquake"))
```

We should be worried about the observations that have missing data for the `incident_type` variable because what if they are not a fire incident. Hence, I made sure to check the `incident_name` manually to ensure all of the observations in our data set were only fire incidents.

Furthermore, since acres burned will be our response variable we must make sure we are only looking at fires that were already contained so that we know exactly how many acres were affected. Hence, the chunk below removes all the fire incidents that were still active as of May 2025. In this case, there were only three.

```{r}
fire_data <- fire_data %>%
  filter(!is_active %in% c("Y"))
```

Moreover, since we are only looking at fire incidents back to twelve years ago, starting from 2013, I must apply a filter to remove the reported fires before that year. Also, I should apply a filter to remove the fires of 2025 later on when attempting to make inference about the fire severity trend over the years, because the graph might be misleading since we are in May and hence the count of fires will be significantly smaller than other years. For simplicity, I will apply those filters later on when I create the variable `year`. The reason why we picked 2013 as the starting year is because it is when the reporting data became regular and consistent. Before, there were only two fires incidents from 1969 and one from 2009.

Lastly, I must make sure the fire location, `incident_county`, is only considering California counties. After manually analyzing that variable, I did find that some reported fires are from Mexico and State of Nevada. This might have happened since the country and state are close to the border. Thus, we shall remove them manually:

```{r}
fire_data <- fire_data %>%
  filter(!incident_county %in% c("Mexico, San Diego", "Nevada", "State of Nevada", "Nevada, Placer"))
```

### Variable Selection

Now, let's take a look at the variables in the original data set provided by CalFIRE and understand the variables we are working with:

```{r}
head(original_fire, 10)
colnames(original_fire)
```

We can see there are some unnecessary variables that can be removed from this data set because they will be irrelevant to our analysis. More specifically:

-   `incident_is_final` - I am only considering incidents that are final because days active is one of my predictor variables. Plus, there were only 3 fires that were active on the data set. They will be deleted in the chunks below.

-   `incident_date_last_update` - Irrelevant for our analysis since fires considered are final.

-   `incident_county` - I modified this variable to only include counties in California.

-   `incident_location` - This column described the location of the fire, some cells described which freeway, other cells described off of which street, other cells gave more estimations (i.e. near the 4500 block of Chuckwagon Drive, Copperopolis). It would be very ambitious to consider this a variable.

-   `incident_containment` - This column showed what percentage of the fire was contained, while 2794 out of 2864 were contained, the data showed 70 cells with missing data or less than 100% contained. However, this seems to be a variable that was not updated because all of those 70 fires were extinguished already, hence they have to have been contained.

-   `incident_longitude` and `incident_latitude` - Irrelevant for our analysis, no need for the location of the fire to be this specific.

-   `incident_type` - The original data set did contain two floods and one earthquake incidents that I deleted for the polished excel file. Also, this variable differentiated fire from wildfire. Since we are not getting that specific I decided to drop this variable as well.

-   `incident_date_extinguished` and `incident_dateonly_extinguished` - I was going to use this variable to calculate for how long each fire has been active. However, after some digging, I found multiple inconsistencies in the reportedly duration of the fire. Some of them showed that they were active for more than a year! Plus, I found that if we consider `incident_date_extinguished` , near half of the fires supposedly were active for more than 60 days, which does not sound reasonable at all. However, I did not lose hope with this data set from CalFIRE because the `incident_date_created` has been precisely accurate with every fire I researched on my own. Similarly with `acres_burned` .

-   `incident_date_created` - Repetitive, we already have `incident_dateonly_created`.

-   `incident_administrative_unit` , `incident_administrative_unit_url`, `incident_control` , `incident_cooperating_agencies` , `incident_id` , `incident_url`, `calfire_incident` , `notification_desired` - Irrelevant for our analysis.

Let's create a new data set with those variables removed:

```{r}
fire_data <- fire_data %>%
  select(-c(incident_is_final, incident_date_last_update, incident_location, incident_containment, incident_longitude, incident_latitude, incident_type, incident_date_extinguished, incident_dateonly_extinguished, incident_administrative_unit, incident_administrative_unit_url, incident_control, incident_cooperating_agencies, incident_id , incident_url, calfire_incident, notification_desired, incident_date_created, is_active))

# To remove all the variables we deemed unecessary.
```

Now that we have removed those unnecessary variables. Let's extract other interesting variables from the given ones and perhaps change their names for our data set to look more professional. For example, from the date the fire was created we can extract the year, the month, and the season that fire originated. Hence, here are the variables we are creating from the given data:

-   `year` - what year the fire originated.

-   `month` - what month the fire originated in numeric form.

-   `season` - what was the season when the fire originated.

-   `is_complex` - a fire is called a "complex" when two or more fires burn in the same general area and are managed under a single incident command or unified command.

```{r}
fire_data <- fire_data %>%
  mutate(
    year = year(incident_dateonly_created),
    month = factor(month(incident_dateonly_created),
                   levels = 1:12,
                   labels = c("Jan", "Feb", "Mar", "Apr", "May",
                              "Jun","Jul", "Aug", "Sep", "Oct",
                              "Nov", "Dec")),
    season = case_when(
      month %in% c("Dec", "Jan", "Feb") ~ "Winter",
      month %in% c("Mar", "Apr", "May")  ~ "Spring",
      month %in% c("Jun", "Jul", "Aug")  ~ "Summer",
      month %in% c("Sep", "Oct", "Nov") ~ "Fall",
      TRUE ~ NA_character_
    ),
    
    is_complex = grepl("Complex", incident_name)
  )
```

Now we can easily apply the filter to `year` and only consider fires from 2013 to 2024.

```{r}
fire_data <- fire_data %>%
  filter(year >= 2013)
```

Now, let's change some of the variables names for aesthetic:

```{r}
fire_data <- fire_data %>%
  rename(
    name = incident_name,
    county = incident_county,
    severity = incident_acres_burned,
    date = incident_dateonly_created,
  )
```

Finally, let's take a look at our updated and clean data set. We are now one step closer to perform our Analysis.

```{r}
head(fire_data, 10)
colnames(fire_data)
```

## Exploratory Data Analysis

In this section, we will explore our variables by looking at their distributions and relationship between our categorical variables and our response variable, `severity`.

### Missing Data

Before exploring our variables, we must address how much of the data is missing and how can we tackle this problem.

```{r}
    fire_data |>
      miss_var_summary()
```

Hence, we have 61 missing data points in total in our data. More precisely, 51 reports missing for `severity` (acres burned) and 10 reports missing for `county` (fire incident county), which represents about 1.80% and 0.35% of those variables, respectively, total reported data. Therefore, this is a good sign that our data set has barely any data missing. We could even visualize how insignificant the missingness is related to our overall data,

```{r}
#| warning: false
#| message: false

vis_miss(fire_data, cluster = TRUE, sort_miss = TRUE)

gg_miss_upset(fire_data,
              nsets = 9)
```

Therefore, approximately 2% of the data had missing values. I opted to remove those rows. This avoids the need for potentially biased imputation of the target variable, with methods such as *Mean/Median/Mode*, *linear model*, or *softImpute*. The small proportion of missing data will not significantly impact our overall analysis.

Moreover, we it is plausible to ignore the missing data because the "upset" plot indicated that the variables do not tend to be missing together. Hence, this strengthen, but does not prove, our assumption that the data can be treated as Missing Completely at Random (MCAR).

```{r}
#| warning: false
#| message: false

fire_data <- fire_data %>% 
  drop_na()
```

```{r}
#| warning: false
#| message: false

    fire_data |>
      miss_var_summary()
```

Hence, we now have a clean data set with 2,766 fire incidents across California with no missing data.

### Data Split

Furthermore, we should split the data into a training set (`fire_train`) and test set (`fire_test`). The recommended amount of data in the training set is roughly 80% for a random split, thus we shall follow that. We must apply this split for several reasons, more importantly, to prevent over fitting and to evaluate/compare models accurately. Our test set is extremely important because it acts like "new" data, helping us check if the trained model generalizes. Also, since we are planning on making inference claims, we must make sure our model's conclusions are not specific to the training set only.

```{r}
#| warning: false
#| message: false

set.seed(437)

n <- nrow(fire_data)
train_indices <- sample(n, size = floor(0.8*n))

fire_train <- fire_data[train_indices,]
fire_test <- fire_data[-train_indices,]

```

### Exploring Variables

Let's take a look at our response variable:

```{r}
#| warning: false
#| message: false

fire_train |>
  summarize(
    num_total = n(),
    mean = mean(severity),
    sd = sd(severity),
    min = min(severity),
    Q1 = quantile(severity, 0.25),
    median = median(severity),
    Q3 = quantile(severity, 0.75),
    max = max(severity)
    )
```

Hence, this tell us that from the 2,212 fires observed in our training set, 50% of them burned between 30 and 338 acres, with 25% of fires burning less than 30 acres and 25% of fires burning more than 338 acres. Notice how the average (mean) of acres burned is around 4,320 acres which is much higher than the median of 83 acres. This implies that half of the fires burn 85 acres or less, however there are a few massive fires (outliers) that are significantly shifting the average. Plus, the standard deviation is extremely high, around 37,221 acres. This suggests a very strong right skewness for the distribution of `severity` .

Furthermore, notice how we have observations of fires that burned 0 acres and a fire that was able to reach the incredible 1,032,648 acres mark. This extreme difference between fire severity explain the variability in the data, together with he standard deviation. In fact, in other to show the plot of `severity` we need to apply a Logarithmic Scale to compress those extreme values and allow us to visualize and interpret the full distribution of `severity` .

```{r eval= FALSE}
#| warning: false
#| message: false

ggplot(fire_train, aes(x = severity)) +
  geom_histogram(bins = 70, fill = "purple", color = "black") +
  scale_x_log10() +
  labs(title = "Distribution of Fire Severity (Log Scale)", x = "Severity", y = "Count of Fires") +
  theme_minimal()
```

As predicted, `severity` has a clear right-skewed distribution. Here is how to interpret the Log Scale:

| Notation | Acres Burned |
|----------|--------------|
| 1e+01    | 10           |
| 1e+02    | 100          |
| 1e+03    | 1,000        |
| 1e+04    | 10,000       |
| 1e+05    | 100,000      |
| 1e+06    | 1,000,000    |

Hence, the histogram reveals that the great majority of fires in our training set burn between 10 to 1,000 acres. Including an extreme "high peak" at a little before 100 acres, which explains the median of 83 from our Summary.

Now, let's compare the `severity` of the fires by `season` of the year:

```{r}
#| warning: false
#| message: false

ggplot(fire_train, aes(x = season, y = severity)) +
  geom_boxplot(fill = "purple") +
  scale_y_log10() +
  labs(
    title = "Severity of Fires by Season (Log Scale)",
    x = "Season",
    y = "Severity"
  ) +
  theme_minimal()
```

Hence, we can see that the median fire severity appears consistent across the seasons, with about half of the fires in each season burned around or a little below 100 acres. However, Fall and Summer demonstrate to have the most outliers (extreme fire events) with severity well above 10,000 acres and even reaching up to over 1,000,000 acres, in Summer. This strongly suggests that while the typical size of fire in our training set do not vary much across seasons, the most severe fires tend to happen during Summer and Fall.

```{r}
fire_train |>
group_by(season) |>
summarize(
num_total = n(),
mean = mean(severity),
sd = sd(severity),
min = min(severity),
Q1 = quantile(severity, 0.25),
median = median(severity),
Q3 = quantile(severity, 0.75),
max = max(severity)
)
```

More precisely, notice how many more fires happened in California during Summer compared to the other seasons, 1,400 fire incidents representing around 63% of the fires in our training set. Hence, this suggests that fire incidents in our training set tend to happen significantly more often during the Summer than other seasons.

What if we look at the fire severity over the years. However, we must be careful to not include the fire incidents from 2025 since we are only in the middle of the year and the amount of fires will most likely be less than other years. Hence, including those could cause a misleading plot. Thus, we will subset the rows of `fire_train` to not include the incidents from 2025.

[**Note**]{.underline}: We did not just remove the fires from 2025 from `fire_data` , the whole data set, because the data was useful for us to plot the `severity` distribution and to analyze its relationship with `season` .

```{r}
fire_over_years <- fire_data |> 
  filter(year <= 2024)
```

```{r}
fire_over_years |>
group_by(year) |>
summarize(
num_total = n(),
mean = mean(severity),
sd = sd(severity),
min = min(severity),
Q1 = quantile(severity, 0.25),
median = median(severity),
Q3 = quantile(severity, 0.75),
max = max(severity)
)
```

```{r eval=FALSE}
#| warning: false
#| message: false

ggplot(
  data = fire_over_years,
  mapping = aes(
    x = year, 
    y = severity
    )
  ) +
  
  geom_point(
    alpha = 0.2
    ) +
  
  geom_smooth(method = "loess", se = FALSE, color = "tomato") +
  
  scale_y_log10() +
  scale_x_continuous(breaks = seq(2013, 2024, 1)) +
  
  labs(title = "Fire Severity Over Time",
       x = "Years",
       y = "Severity (Log Scale)"
       )

```

Hence, this plot suggests that `year` have a slight effect on `severity` .

[**OBS**]{.underline}: Our choice of alpha here, "`alpha = 0.2`" is to reduce the opacity of the data points and make them more readable.

```{r}
#| warning: false
#| message: false

ggplot(data = fire_train, 
       mapping = aes(
         x = season,
         y = severity
         )
       ) +
    scale_y_log10() +
  geom_boxplot(fill = "purple") + 
  geom_point(aes(color = year), 
             alpha = 0.8
             )
```

### Complex Fires

As we have noticed from the `severity` 's histogram and 5-number summary, the great majority of fires burned below 500 acres. The ones that end up burning above 500 acres are definitely skewing the `severity` distribution and its average. Let's analyze how does the `is_complex` variable affect the trends in our results. Hence, let's analyze if the "non-complex fires", the ones that do not do not classify as complex are skewing our results. It's plausible to assume they might skew our data since it would make sense that complex fires might have a bigger severity than others, since they normally consist of two or more fires in the same area. It sounds reasonable that they could most likely outburn other non-complex fires. Thus, let's explore further:

```{r}
#| warning: false
#| message: false

fire_train |> 
  select(name, severity, is_complex, county, year) |> 
  filter(severity > 500)
```

Hence, out of the 2212 fire incidents in our training set, only 464 indicate a severity higher than 500 acres. Representing around 21% of the fires in the training set. Including the ultimate outlier of this entire data set, the *August Complex* from 2020, a fire so devastating that burned 1,032,648 acres.

Which again, it means that two or more fires burned in the same general area and were managed under a single incident command or unified command.

It might be interesting to check how the distribution of `severity` would look like without these extreme fire incidents. Thus,

```{r}
#| warning: false
#| message: false

fire_non_extreme <- fire_data |> 
  filter(severity <= 500)

fire_non_extreme |>
  summarize(
    num_total = n(),
    mean = mean(severity),
    sd = sd(severity),
    min = min(severity),
    Q1 = quantile(severity, 0.25),
    median = median(severity),
    Q3 = quantile(severity, 0.75),
    max = max(severity)
    )

ggplot(fire_non_extreme, aes(x = severity)) +
  
  geom_histogram(bins = 70, fill = "purple", color = "black") +

  labs(title = "Distribution of Non-Complex Fire Severity", x = "Severity", y = "Count of Fires") +
  
  theme_minimal()
```

Hence, the distribution of `severity` shifted a little bit to the center. However, it still shows a right-skewed distribution and considerable variability that is explained by the 106 acres standard deviation and this time not so absurd difference between the average (96 acres) vs the median (53 acres).

Furthermore, let's check if `is_complex` affects `severity`:

```{r}
#| warning: false
#| message: false

fire_train |>
group_by(is_complex) |>
summarize(
num_total = n(),
mean = mean(severity),
sd = sd(severity),
min = min(severity),
Q1 = quantile(severity, 0.25),
median = median(severity),
Q3 = quantile(severity, 0.75),
max = max(severity)
)

ggplot(fire_train, aes(x = is_complex, y = severity)) +
  geom_boxplot(fill = "orange") +
      scale_y_log10() +

  labs(
    title = "Severity of Fires by Season (Log Scale)",
    x = "Complex",
    y = "Severity"
  ) +
  theme_minimal()
```

Even though there are only 41 Complex fires out of 2212 fires in our training set, the median and mean of the Complex fires are extremely higher than of the regular fires. More specifically, the median of Complex fires is 12,503 acres vs the median of the regular fires is 80 acres. Therefore, it is recommended to move forward to our modeling while considering the complex fire incidents, because according to the box plots and 5-number summary, they do seem to show a significant effect in severity. Hence, they are important for our analysis since severity is our response variable.

## Modeling

## Insights

### Limitations and Future Work

### Reflection
